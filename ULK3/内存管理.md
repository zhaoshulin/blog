#内存管理

----------
RAM被分为两部分：

1. 一小部分永久被Kernel占用：存放Kernel代码和静态内核数据结构
2. 其余部分叫动态内存：需要进行有效的管理

下图为 硬件保留内存、 Kernel保留内存 和 动态内存的示意图：

![](http://i.imgur.com/ZXpWxut.jpg)

##页框管理
- Linux采用4KB页框大小作为内存分配的基本单元，原因是：
	1. 造成缺页异常就两种原因：
		1. 请求的页存在，但进程无权访问
		2. 请求的页不存在
	2. 当memory和disk之间传输小数据块时，4KB比4MB更好

###页描述符

- 页描述符的作用：记录每个页框的状态
- _count：页的引用计数器：
	- _count = -1：页框空闲
	- _count >= 0：页框被分配给了一个或多个进程；或者用于保存内核数据结果
- PG_reserved标志：页框被留给Kernel或者不能被使用

###NUMA：非一致内存访问

- 一个特定的CPU对不同node的访问时间不同
- 每个node又可以分为不同的zone

###内存管理区（zone）

- 理想情况下，任何类型的数据页都可以放在任何页框中，但这不可能，因为有两种硬件限制：
	1. DMA只能访问前16MB
	2. 32位CPU因为线性地址空间太小，所以不能访问所有的物理内存
- 为了克服这两个限制，Kernel把物理内存划分为三个zone：
	1. ZONE_DMA： 0 - 16MB
	2. ZONE_NORMAL： 16MB - 896MB
	3. ZONE_HIGHMEM： > 896MB
- 把ZONE_DMA和ZONE_NORMAL线性映射到第4个GB之后，Kernel就可以直接访问他们了
- 尽管ZONE_HIGHMEM也被线性映射到第4个GB，Kernel还是不能直接访问他
- 64位架构上ZONE_HIGHMEM总是空的，因为可使用的内核线性地址空间远大于市面上所有的RAM！
- 自旋锁保护 管理区描述符
- Kernel使用zonelist来为内存分配请求指定首选的zone

###保留的页框池

- 有两种内存分配请求
	1. 普通的请求：如果内存不足，回收一些，阻塞发出这个请求的内核控制路径，直到有了足够的内存
	2. 原子内存分配请求：从不阻塞！
- 为了尽量保证原子内存分配请求可以成功，Kernel为原子内存分配请求保留了一个页框池，只有在内存不足时使用
- pages_min：保留页框的数目
- 保留池的大小公式：

![](http://i.imgur.com/qD1zej9.jpg)

###分区页框分配器
- 目的：处理对 连续页框组 的内存分配请求
- zoned page frame allocator 的组成如下图：

![](http://i.imgur.com/JOhyUcQ.jpg)

- 管理区分配器：接受请求；搜索一个可以满足请求的管理区
- 在这个管理区中，伙伴系统：处理页框
- 每CPU页框cache：缓存页框
- 用于请求页框的标志：
	- DMA=1：只能从ZONE\_DMA里面分配
	- HIGHMEM=0：按优先顺序从ZONE\_NORMAL、ZONE\_DMA里面分配
	- HIGHMEM=1：按优先顺序从ZONE\_HIGHMEM、ZONE\_NORMAL、ZONE\_DMA里面分配
	- WAIT：可以阻塞进程
	- HIGH：允许访问 保留的页框池
	- REPEAT：重试，直到分配成功
	- NORETRY：一次分配失败后就不再重试了
	- ZERO：分配到的页框都要被初始化为0

###高端内存页框的内核映射
- 为什么需要映射高端内存？
- 因为32位架构，内核只能直接访问到前896MB，如果没有映射，高端内存都不存在页框的线性地址！
- 注意：我的目的是：根据高端内存的页框**page**，得到它被映射进的内核线性地址**address**
- 解决方案1：分配时，不返回页框的线性地址，而返回页框的页描述符的线性地址（页描述符在内核初始化的时候就被永久固定分配在低端内存中了）
- 解决方案2：使用内核线性地址空间中的最后128MB，专门用于映射高端内存页框！（暂时的，所以没办法在同一时刻访问所有的高端内存，只能映射一部分再访问一部分）
- **高端内存页框 ---> 内核最后128MB线性地址空间** 的三种机制：
	1. 永久内核映射（阻塞）
	2. 临时内核映射（非阻塞）
	3. 非连续内存区管理
- 但是都无法保证对整个RAM同时进行寻找
- 因为：毕竟只有128MB的线性地址留给映射高端内存，而PAG支持高达64GB的RAM！

####永久内核映射: kmap（阻塞）
#####pkmap_count计数器
1. 计数器=0：该页表项还没映射任何高端内存页框呢，可以使用！（处女）
2. 计数器=1：该页表项还没映射任何高端内存页框呢，但不可使用！（因为TLB还没被刷新）
3. 计数器=n（n远大于1）：该页表项已经映射了一个高端内存页框，目前有（n-1）个内核成分在使用这个内存页框

#####page\_address\_htable
这个哈希表中存放的是：

- key：高端内存的页框page
- value：被映射到的内核线性地址address

#####page_address()：

- 入参：page
- 返回：address或NULL
- 执行过程：
	1. 如果这个page不在高端内存中（即：PG_highmem=0）：直接计算得到其线性地址：

			__va((unsigned long) (page - mem_map) << 12);
	2. 如果这个page在高端内存中：
		1. 检查page\_address\_htable哈希表，如果存在，读取该表，返回线性地址
		2. 如果不在哈希表中，返回NULL

#####map\_new\_virtual()：

- 入参：page
- 返回：address
- 作用：page已经确定了在高端内存中，并且还没有被映射过；那么我就要第一次处理好 page--->address 的映射了
- 执行过程：
	1. 找到一个计数器=0的未使用页表项
	2. 将这个页表项与page挂钩
	3. 计数器=1
	4. 返回该页表项的address
- 注意：如果第一次遍历没找到计数器=0的页表项，则调用flush\_all\_zero\_pkmaps()：
	1. 遍历找到计数器=1的所有页表项（未映射，但TLB还没刷新）
	2. 计数器=0
	3. 删除哈希表中的这一项
	4. TLB刷新

####临时内核映射: kmap\_atomic（不阻塞）
- 每个CPU都有13个窗口，通过这个窗口可以实现 page ---> address
- 同一个窗口永不会被两个不同的控制路径同时使用

###伙伴系统算法
- 目的：解决因为分配一组连续的页框而产生的“外碎片”问题
- 伙伴：试图把大小为 x 的一对空闲伙伴块合并为一个大小为 2x 的单独块，需要满足：
	1. 两个块大小一样，都是 x
	2. 物理地址连续
	3. 第一个块的第一个页框的物理地址是 2\*x\*2^12 的倍数
- 把所有的空闲页分组为11个链表： 1 2 4 8 16 32 64 128 256 512 1024 个连续的页框（由order来指定级数）
- 每个 zone 都有各自的 伙伴系统
- 分配块的步骤：
	1. 首先需要保证已经 禁止了本地中断；获取了自旋锁
	2. 扫描给定order的链表
	3. 如果没有，则继续扫描更大的order链表
	4. 找到后，空闲页框计数器-1，更新链表，返回第一个页框地址
- 释放块的步骤：
	1. 首先需要保证已经 禁止了本地中断；获取了自旋锁
	2. 尽量找到它的buddy页，合并，更新链表
	3. 最多循环10次

###每CPU页框cache
- 目的：预先分配，快速满足 单个页框 的请求
- 两个cache：
	1. 热cache：CPU很快就要用到
	2. 冷cache：DMA用，不会涉及到CPU
- cache的大小调整（利用low和high）：
	- cache中页框<low：从伙伴系统中分配batch个单一页框来补充
	- cache中页框>high：从cache中释放batch个单一页框到伙伴系统中

- 通过 每CPU页框cache 来分配页框
	- GFP_COLD=0：从热cache中获取
	- GFP_COLD=1：从冷cache中获取
	- 如果order不等于0，cache不能用，只能绕过cache，从伙伴系统中来分配吧
	- 正常情况 与disk cache的工作模式类似

- 释放页框到 每CPU页框cache
	- free\_cold\_page()：页框 ---> 伙伴系统； 页框 ---> 冷cache
	- hot\_hot\_page()：页框 ---> 伙伴系统； 页框 ---> 热cache

##内存区管理

- 如果只是为了存放几个字节而给它分配一个整页框，这尼玛是浪费！
- 伙伴系统解决的是对大块内存的请求
- slab分配器解决的是对小块内存的请求

###slab分配器
- slab分配器借用了C++的思想：
	- object：内存区
	- 构造：初始化内存区
	- 析构：回收内存区
- 当回收内存区时，slab不丢弃，而是把刚用到的页框放到了cache中
- 如果有某个进程犯贱，一直请求非2次幂（比如，3）的内存，那么slab会创建一组大小是3的对象，专门用于伺候这个贱人进程，解决“内碎片”
- 伙伴系统每次被调用都会弄脏TLB
- slab分配器的组成如下图：

![](http://i.imgur.com/G9yDMt1.jpg)

- slabs_free：只包含空闲对象的slab描述符双向循环链表
- slabs_full：只包含非空闲对象的slab描述符双向循环链表
- slabs_partial：既包含空闲对象 又包含非空闲对象的slab描述符双向循环链表
- 高速缓存描述符 与 slab描述符 之间的关系图如下：

![](http://i.imgur.com/QRgSYo6.jpg)

- cache分为两类：
	- 普通cache：只用于slab分配器
	- 专用cache：可供Kernel其他部分使用

### slab分配器 <---> 分区页框分配器

- 当slab分配器需要创建一个新的slab时，它调用 分区页框分配器 来获得一组连续的空闲页框。
- 分配一个slab的具体步骤：
	1. alloc page
	2. 设置 大小order
	3. 计数器 ++
	4. SetPageSlab

- 释放一个slab的具体步骤：
	1. ClearPageSlab
	2. free page
	3. 计数器 --

